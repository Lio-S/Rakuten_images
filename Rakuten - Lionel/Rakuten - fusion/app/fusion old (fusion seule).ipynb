{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b1052ddb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/elion/.pyenv/versions/3.10.12/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU disponible : Quadro M1200\n",
      "CUDA Memory: 0.00GB / 0.00GB\n",
      "1. Configuration et chargement des données..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-22 10:24:28,813 - classification_pipeline - INFO - Chargement des features pré-calculées...\n",
      "2025-05-22 10:24:29,880 - classification_pipeline - INFO - Chargement effectué avec succès.\n",
      "2025-05-22 10:24:30,843 - classification_pipeline - INFO - Indices sauvegardés dans data/indices\n",
      "2025-05-22 10:24:30,845 - classification_pipeline - INFO - Distribution des indices:\n",
      "2025-05-22 10:24:30,847 - classification_pipeline - INFO -   - Total: 84916\n",
      "2025-05-22 10:24:30,849 - classification_pipeline - INFO -   - Test: 16984 (20.0%)\n",
      "2025-05-22 10:24:30,850 - classification_pipeline - INFO -   - Train original: 67932 (80.0%)\n",
      "2025-05-22 10:24:30,853 - classification_pipeline - INFO -   - Train balanced (unique): 44050 (51.9%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Erreur lors de l'exécution: object of type 'int' has no len()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_1469/4260016239.py\", line 605, in <module>\n",
      "    indices_dict = pipeline.extract_and_save_indices()\n",
      "  File \"/home/elion/Dev_IA/Rakuten/app/preprocess.py\", line 2196, in extract_and_save_indices\n",
      "    ({len(train_balanced_indices)/len(len(train_balanced_indices) - len(train_balanced_unique))*100:.1f}%)\")\n",
      "TypeError: object of type 'int' has no len()\n"
     ]
    }
   ],
   "source": [
    "from preprocess import ProductClassificationPipeline, PipelineConfig\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import yaml\n",
    "import matplotlib.pyplot as plt\n",
    "import shap\n",
    "import torch\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "# URL temporaire pour les données texte (à remplacer par la vôtre)\n",
    "url_texte = \"https://drive.google.com/file/d/1fakeurl123456789/view?usp=sharing\"\n",
    "\n",
    "def load_model_configs():\n",
    "    \"\"\"\n",
    "    Charge les configurations des modèles depuis le YAML\n",
    "    \n",
    "    Returns:\n",
    "        dict: Configurations des modèles avec leurs paramètres\n",
    "    \"\"\"\n",
    "    try:\n",
    "        config_path = os.path.join('data', 'models', 'model_configs.yaml')\n",
    "        with open(config_path, 'r', encoding='utf-8') as f:\n",
    "            configs = yaml.safe_load(f)\n",
    "        \n",
    "        # Vérification de la présence de tous les modèles attendus\n",
    "        expected_models = {'xgboost', 'neural_net', 'SVM'}\n",
    "        missing_models = expected_models - set(configs.keys())\n",
    "        \n",
    "        if missing_models:\n",
    "            print(f\"Attention : modèles manquants dans la configuration : {missing_models}\")\n",
    "            \n",
    "        return configs\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Erreur lors du chargement des configurations : {str(e)}\")\n",
    "        return {}\n",
    "\n",
    "def load_models(pipeline, model_names=['xgboost', 'neural_net', 'SVM']):\n",
    "    \"\"\"\n",
    "    Charge les modèles spécifiés\n",
    "    \n",
    "    Args:\n",
    "        pipeline: Pipeline de classification\n",
    "        model_names: Liste des noms de modèles à charger\n",
    "        \n",
    "    Returns:\n",
    "        dict: Dictionnaire contenant les modèles chargés\n",
    "    \"\"\"\n",
    "    models = {}\n",
    "    \n",
    "    for model_name in model_names:\n",
    "        try:\n",
    "            pipeline.load_model(model_name)\n",
    "            models[model_name] = pipeline.model\n",
    "            print(f\"Modèle {model_name} chargé avec succès\")\n",
    "        except Exception as e:\n",
    "            print(f\"Erreur lors du chargement du modèle {model_name}: {str(e)}\")\n",
    "    \n",
    "    return models\n",
    "\n",
    "def fuse_predictions(text_probs, image_probs, strategy='mean'):\n",
    "    \"\"\"\n",
    "    Fusionne les prédictions texte et image selon différentes stratégies\n",
    "    \n",
    "    Args:\n",
    "        text_probs: Probabilités du modèle texte\n",
    "        image_probs: Probabilités du modèle image\n",
    "        strategy: Stratégie de fusion ('mean', 'product', 'max', 'weighted', 'confidence_weighted')\n",
    "        \n",
    "    Returns:\n",
    "        np.array: Probabilités fusionnées\n",
    "    \"\"\"\n",
    "    if strategy == 'mean':\n",
    "        return (text_probs + image_probs) / 2\n",
    "    elif strategy == 'product':\n",
    "        return text_probs * image_probs\n",
    "    elif strategy == 'max':\n",
    "        return np.maximum(text_probs, image_probs)\n",
    "    elif strategy == 'weighted':\n",
    "        # Pondération fixe 60% texte, 40% image (à ajuster selon tests)\n",
    "        return text_probs * 0.6 + image_probs * 0.4\n",
    "    elif strategy == 'confidence_weighted':\n",
    "        # Pondération dynamique basée sur la confiance de chaque modèle\n",
    "        return fuse_predictions_confidence_weighted(text_probs, image_probs)\n",
    "    else:\n",
    "        raise ValueError(f\"Stratégie de fusion {strategy} non supportée\")\n",
    "\n",
    "def fuse_predictions_confidence_weighted(text_probs, image_probs):\n",
    "    \"\"\"\n",
    "    Fusionne les prédictions en utilisant la confiance de chaque modèle comme poids dynamique\n",
    "    \n",
    "    Args:\n",
    "        text_probs: Probabilités du modèle texte\n",
    "        image_probs: Probabilités du modèle image\n",
    "        \n",
    "    Returns:\n",
    "        np.array: Probabilités fusionnées\n",
    "    \"\"\"\n",
    "    # 1. Obtenir la confiance de chaque modèle (probabilité max pour chaque exemple)\n",
    "    text_confidence = np.max(text_probs, axis=1, keepdims=True)\n",
    "    image_confidence = np.max(image_probs, axis=1, keepdims=True)\n",
    "    \n",
    "    # 2. Normaliser les confidences pour obtenir les poids\n",
    "    total_confidence = text_confidence + image_confidence\n",
    "    text_weights = text_confidence / total_confidence\n",
    "    image_weights = image_confidence / total_confidence\n",
    "    \n",
    "    # 3. Appliquer les poids spécifiques à chaque exemple\n",
    "    weighted_text_probs = text_probs * text_weights\n",
    "    weighted_image_probs = image_probs * image_weights\n",
    "    \n",
    "    # 4. Combiner les probabilités pondérées\n",
    "    fused_probs = weighted_text_probs + weighted_image_probs\n",
    "    \n",
    "    return fused_probs\n",
    "\n",
    "def evaluate_multimodal_combinations(pipeline, text_model, image_models, X_text_test, X_image_test, y_test, idx_to_category):\n",
    "    \"\"\"\n",
    "    Évalue différentes combinaisons de modèles multimodaux en utilisant les méthodes du pipeline\n",
    "    \n",
    "    Args:\n",
    "        pipeline: Instance de ProductClassificationPipeline\n",
    "        text_model: Modèle de texte\n",
    "        image_models: Dictionnaire de modèles d'image\n",
    "        X_text_test: Données de test texte\n",
    "        X_image_test: Données de test image\n",
    "        y_test: Vérité terrain\n",
    "        idx_to_category: Mapping des indices vers les catégories\n",
    "    \"\"\"\n",
    "    results = {}\n",
    "    fusion_strategies = ['mean', 'product', 'weighted', 'max', 'confidence_weighted']\n",
    "    print(f\"Dimensions originales: X_text_test={len(X_text_test)}, X_image_test={len(X_image_test)}\")\n",
    "    \n",
    "    category_to_idx = {code: idx for idx, code in idx_to_category.items()}\n",
    "    \n",
    "    # Vérifier que les dimensions correspondent\n",
    "    if len(X_text_test) != len(X_image_test) or len(X_text_test) != len(y_test):\n",
    "        print(\"AVERTISSEMENT: Les dimensions ne correspondent toujours pas!\")\n",
    "        min_size = min(len(X_text_test), len(X_image_test), len(y_test))\n",
    "        text_input = X_text_test.iloc[:min_size] if hasattr(X_text_test, 'iloc') else X_text_test[:min_size]\n",
    "        X_image_test = X_image_test[:min_size]\n",
    "        y_test = y_test[:min_size]\n",
    "    else:\n",
    "        text_input = X_text_test\n",
    "    \n",
    "    # Obtenir les prédictions texte en utilisant le modèle SVM\n",
    "    print(\"Génération des prédictions texte...\")\n",
    "    try:\n",
    "        if isinstance(text_input, pd.Series):\n",
    "            text_data = text_input.values.tolist()\n",
    "        else:\n",
    "            text_data = text_input\n",
    "            \n",
    "        # Prédictions directes avec le modèle de texte\n",
    "        if hasattr(text_model, 'predict'):\n",
    "            text_preds = text_model.predict(text_data)\n",
    "            text_probs = text_model.predict_proba(text_data)\n",
    "        else:\n",
    "            # Si c'est un pipeline personnalisé\n",
    "            pipeline.model = text_model\n",
    "            text_preds, text_probs = pipeline.predict(text_data)\n",
    "    except Exception as e:\n",
    "        print(f\"Erreur lors de la prédiction texte: {e}\")\n",
    "        # Fallback pour les erreurs\n",
    "        num_classes = len(idx_to_category)\n",
    "        text_preds = np.random.randint(0, num_classes, size=len(text_input))\n",
    "        text_probs = np.random.random((len(text_input), num_classes))\n",
    "        text_probs = text_probs / text_probs.sum(axis=1, keepdims=True)\n",
    "    \n",
    "    # Convertir les prédictions en indices si nécessaire\n",
    "    if isinstance(text_preds[0], (int, np.integer)) and max(text_preds) < 100:\n",
    "        # C'est déjà des indices\n",
    "        text_preds_idx = text_preds\n",
    "    else:\n",
    "        # Convertir les codes de catégorie en indices\n",
    "        text_preds_idx = np.array([category_to_idx.get(code, 0) for code in text_preds])\n",
    "    \n",
    "    # Même chose pour y_test\n",
    "    if isinstance(y_test[0], (int, np.integer)) and max(y_test) < 100:\n",
    "        y_test_idx = y_test\n",
    "    else:\n",
    "        y_test_idx = np.array([category_to_idx.get(code, 0) for code in y_test])\n",
    "    \n",
    "    # Calcul des métriques texte\n",
    "    text_accuracy = accuracy_score(y_test_idx, text_preds_idx)\n",
    "    text_f1 = f1_score(y_test_idx, text_preds_idx, average='weighted')\n",
    "    \n",
    "    text_results = {\n",
    "        \"accuracy\": text_accuracy,\n",
    "        \"weighted_f1\": text_f1\n",
    "    }\n",
    "    results[\"text_only\"] = text_results\n",
    "    print(f\"Texte uniquement: accuracy={text_results['accuracy']:.4f}, f1={text_results['weighted_f1']:.4f}\")\n",
    "    \n",
    "    # Pour chaque modèle image\n",
    "    for model_name, image_model in image_models.items():\n",
    "        print(f\"Génération des prédictions pour {model_name}...\")\n",
    "        \n",
    "        try:\n",
    "            pipeline.model = image_model\n",
    "            image_preds, image_probs = pipeline.predict(X_image_test)\n",
    "            \n",
    "            # Résultats image uniquement\n",
    "            image_results = {\n",
    "                \"accuracy\": accuracy_score(y_test_idx, image_preds),\n",
    "                \"weighted_f1\": f1_score(y_test_idx, image_preds, average='weighted')\n",
    "            }\n",
    "            results[f\"{model_name}_only\"] = image_results\n",
    "            print(f\"{model_name} uniquement: accuracy={image_results['accuracy']:.4f}, f1={image_results['weighted_f1']:.4f}\")\n",
    "            \n",
    "            # Essayer différentes stratégies de fusion\n",
    "            for strategy in fusion_strategies:\n",
    "                print(f\"Évaluation de la fusion '{strategy}' avec {model_name}...\")\n",
    "                                \n",
    "                fused_probs = fuse_predictions(text_probs, image_probs, strategy)\n",
    "                fused_preds = np.argmax(fused_probs, axis=1)\n",
    "                \n",
    "                fused_results = {\n",
    "                    \"accuracy\": accuracy_score(y_test_idx, fused_preds),\n",
    "                    \"weighted_f1\": f1_score(y_test_idx, fused_preds, average='weighted')\n",
    "                }\n",
    "                \n",
    "                results[f\"{model_name}_{strategy}\"] = fused_results\n",
    "                print(f\"Fusion {model_name} ({strategy}): accuracy={fused_results['accuracy']:.4f}, f1={fused_results['weighted_f1']:.4f}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Erreur avec le modèle {model_name}: {e}\")\n",
    "            results[f\"{model_name}_error\"] = {\"error\": str(e)}\n",
    "    \n",
    "    # Conversion en DataFrame\n",
    "    results_df = pd.DataFrame.from_dict(results, orient='index')\n",
    "    return results_df\n",
    "\n",
    "def explain_text_model(text_model, X_text_sample, feature_names=None):\n",
    "    \"\"\"\n",
    "    Explique le modèle texte avec SHAP\n",
    "    \n",
    "    Args:\n",
    "        text_model: Modèle SVM texte\n",
    "        X_text_sample: Échantillon de données texte\n",
    "        feature_names: Noms des caractéristiques\n",
    "        \n",
    "    Returns:\n",
    "        tuple: Valeurs SHAP et explainer\n",
    "    \"\"\"\n",
    "    print(\"Génération des explications pour le modèle texte...\")\n",
    "    \n",
    "    # Créer un explainer SHAP pour le modèle SVM\n",
    "    explainer = shap.KernelExplainer(text_model.predict_proba, X_text_sample[:50])\n",
    "    \n",
    "    # Calculer les valeurs SHAP\n",
    "    shap_values = explainer.shap_values(X_text_sample[:100])\n",
    "    \n",
    "    # Visualiser les résultats\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    shap.summary_plot(shap_values, X_text_sample[:100], feature_names=feature_names, show=False)\n",
    "    plt.title(\"Explication SHAP pour le modèle texte\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"data/reports/shap_text_model.png\")\n",
    "    \n",
    "    return shap_values, explainer\n",
    "\n",
    "def explain_image_model(model_type, model, X_image_sample, feature_names=None):\n",
    "    \"\"\"\n",
    "    Explique le modèle image avec SHAP\n",
    "    \n",
    "    Args:\n",
    "        model_type: Type de modèle ('xgboost' ou 'neural_net')\n",
    "        model: Modèle d'image\n",
    "        X_image_sample: Échantillon de données image\n",
    "        feature_names: Noms des caractéristiques\n",
    "        \n",
    "    Returns:\n",
    "        tuple: Valeurs SHAP et explainer\n",
    "    \"\"\"\n",
    "    print(f\"Génération des explications pour le modèle {model_type}...\")\n",
    "    \n",
    "    # Différentes approches selon le type de modèle\n",
    "    if model_type == 'xgboost':\n",
    "        # Utiliser TreeExplainer pour XGBoost (plus efficace)\n",
    "        explainer = shap.TreeExplainer(model)\n",
    "        shap_values = explainer.shap_values(X_image_sample[:100])\n",
    "        \n",
    "        # Visualisations\n",
    "        plt.figure(figsize=(12, 8))\n",
    "        shap.summary_plot(shap_values, X_image_sample[:100], feature_names=feature_names, show=False)\n",
    "        plt.title(f\"Explication SHAP pour le modèle {model_type}\")\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f\"data/reports/shap_{model_type}.png\")\n",
    "        \n",
    "        # Feature importance globale\n",
    "        plt.figure(figsize=(12, 8))\n",
    "        plt.barh(range(min(20, len(model.feature_importances_))), \n",
    "                 sorted(model.feature_importances_, reverse=True)[:20])\n",
    "        plt.title(f\"Top 20 caractéristiques importantes pour {model_type}\")\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f\"data/reports/{model_type}_feature_importance.png\")\n",
    "        \n",
    "    elif model_type == 'neural_net':\n",
    "        # Pour MLP on utilise le DeepExplainer\n",
    "        try:\n",
    "            # Conversion en tenseurs PyTorch\n",
    "            background = torch.FloatTensor(X_image_sample[:50]).to(model.device)\n",
    "            test_tensor = torch.FloatTensor(X_image_sample[:100]).to(model.device)\n",
    "            \n",
    "            # Utiliser GradientExplainer à la place de DeepExplainer si disponible\n",
    "            explainer = shap.GradientExplainer(model, background)\n",
    "            shap_values = explainer.shap_values(test_tensor)\n",
    "            \n",
    "            # Visualisations\n",
    "            plt.figure(figsize=(12, 8))\n",
    "            shap.summary_plot(shap_values, X_image_sample[:100], feature_names=feature_names, show=False)\n",
    "            plt.title(f\"Explication SHAP pour le modèle {model_type}\")\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(f\"data/reports/shap_{model_type}.png\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Erreur lors de l'explication du modèle neural_net: {str(e)}\")\n",
    "            print(\"Utilisation du KernelExplainer en secours...\")\n",
    "            \n",
    "            # Utiliser KernelExplainer comme solution de secours\n",
    "            def model_predict(x):\n",
    "                # Convertir les données en tensor PyTorch\n",
    "                x_tensor = torch.FloatTensor(x).to(model.device)\n",
    "                # Obtenir les prédictions du modèle\n",
    "                with torch.no_grad():\n",
    "                    outputs = model(x_tensor)\n",
    "                    probs = torch.softmax(outputs, dim=1)\n",
    "                return probs.cpu().numpy()\n",
    "            \n",
    "            explainer = shap.KernelExplainer(model_predict, X_image_sample[:50])\n",
    "            shap_values = explainer.shap_values(X_image_sample[:100])\n",
    "            \n",
    "            # Visualisations\n",
    "            plt.figure(figsize=(12, 8))\n",
    "            shap.summary_plot(shap_values, X_image_sample[:100], feature_names=feature_names, show=False)\n",
    "            plt.title(f\"Explication SHAP pour le modèle {model_type} (KernelExplainer)\")\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(f\"data/reports/shap_{model_type}_kernel.png\")\n",
    "    \n",
    "    return shap_values, explainer\n",
    "\n",
    "def explain_multimodal(text_model, image_model, model_type, X_text_sample, X_image_sample, \n",
    "                      fusion_strategy='mean', class_names=None):\n",
    "    \"\"\"\n",
    "    Explique le modèle multimodal fusionné\n",
    "    \n",
    "    Args:\n",
    "        text_model: Modèle texte\n",
    "        image_model: Modèle image\n",
    "        model_type: Type du modèle image\n",
    "        X_text_sample: Échantillon de données texte\n",
    "        X_image_sample: Échantillon de données image\n",
    "        fusion_strategy: Stratégie de fusion\n",
    "        class_names: Noms des classes\n",
    "        \n",
    "    Returns:\n",
    "        dict: Résultats d'explication\n",
    "    \"\"\"\n",
    "    print(f\"Explication du modèle multimodal ({model_type}, fusion: {fusion_strategy})...\")\n",
    "    \n",
    "    # Créer une fonction pour prédire avec le modèle fusionné\n",
    "    def fused_predict(x):\n",
    "        # Supposons que x soit divisé en [features_texte, features_image]\n",
    "        # Dans un cas réel, vous voudriez peut-être séparer x en deux parties\n",
    "        text_part = x[:, :X_text_sample.shape[1]]\n",
    "        image_part = x[:, X_text_sample.shape[1]:]\n",
    "        \n",
    "        # Obtenir les prédictions individuelles\n",
    "        text_probs = text_model.predict_proba(text_part)\n",
    "        \n",
    "        if model_type == 'xgboost':\n",
    "            image_probs = image_model.predict_proba(image_part)\n",
    "        else:  # neural_net\n",
    "            image_part_tensor = torch.FloatTensor(image_part).to(image_model.device)\n",
    "            with torch.no_grad():\n",
    "                outputs = image_model(image_part_tensor)\n",
    "                image_probs = torch.softmax(outputs, dim=1).cpu().numpy()\n",
    "        \n",
    "        # Fusionner selon la stratégie\n",
    "        return fuse_predictions(text_probs, image_probs, strategy=fusion_strategy)\n",
    "    \n",
    "    # Combiner les échantillons\n",
    "    combined_sample = np.hstack([X_text_sample[:100], X_image_sample[:100]])\n",
    "    \n",
    "    # Créer l'explainer\n",
    "    explainer = shap.KernelExplainer(fused_predict, combined_sample[:50])\n",
    "    \n",
    "    # Obtenir les valeurs SHAP\n",
    "    shap_values = explainer.shap_values(combined_sample[:100])\n",
    "    \n",
    "    # Créer des noms de features pour meilleure lisibilité\n",
    "    feature_names = [f'text_{i}' for i in range(X_text_sample.shape[1])] + \\\n",
    "                    [f'img_{i}' for i in range(X_image_sample.shape[1])]\n",
    "    \n",
    "    # Visualiser les résultats\n",
    "    plt.figure(figsize=(16, 10))\n",
    "    shap.summary_plot(shap_values, combined_sample, feature_names=feature_names, show=False)\n",
    "    plt.title(f\"Explication SHAP pour le modèle multimodal ({model_type}, {fusion_strategy})\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"data/reports/shap_multimodal_{model_type}_{fusion_strategy}.png\")\n",
    "    \n",
    "    # Analyser l'importance relative texte vs image\n",
    "    text_importance = np.mean(np.abs(np.vstack(shap_values))[:, :X_text_sample.shape[1]])\n",
    "    image_importance = np.mean(np.abs(np.vstack(shap_values))[:, X_text_sample.shape[1]:])\n",
    "    \n",
    "    importance_ratio = {\n",
    "        'text_importance': float(text_importance),\n",
    "        'image_importance': float(image_importance),\n",
    "        'text_percentage': float(text_importance / (text_importance + image_importance) * 100),\n",
    "        'image_percentage': float(image_importance / (text_importance + image_importance) * 100)\n",
    "    }\n",
    "    \n",
    "    print(f\"Importance relative: Texte {importance_ratio['text_percentage']:.2f}%, \"\n",
    "          f\"Image {importance_ratio['image_percentage']:.2f}%\")\n",
    "    \n",
    "    # Créer un graphique de comparaison d'importance\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.bar(['Texte', 'Image'], [importance_ratio['text_percentage'], importance_ratio['image_percentage']])\n",
    "    plt.ylabel('Importance relative (%)')\n",
    "    plt.title(f'Contribution relative des modalités ({model_type}, {fusion_strategy})')\n",
    "    plt.ylim(0, 100)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"data/reports/modalite_importance_{model_type}_{fusion_strategy}.png\")\n",
    "    \n",
    "    return {\n",
    "        'shap_values': shap_values,\n",
    "        'explainer': explainer,\n",
    "        'importance': importance_ratio\n",
    "    }\n",
    "\n",
    "def sample_data_for_explanation(X_text, X_image, y, n_samples=100, stratify=True):\n",
    "    \"\"\"\n",
    "    Échantillonne les données pour l'explication en assurant une représentation de toutes les classes\n",
    "    \n",
    "    Args:\n",
    "        X_text: Données texte\n",
    "        X_image: Données image\n",
    "        y: Étiquettes\n",
    "        n_samples: Nombre d'échantillons à prendre\n",
    "        stratify: Si True, échantillonnage stratifié par classe\n",
    "        \n",
    "    Returns:\n",
    "        tuple: X_text_sample, X_image_sample, y_sample\n",
    "    \"\"\"\n",
    "    if stratify:\n",
    "        from sklearn.model_selection import StratifiedShuffleSplit\n",
    "        \n",
    "        sss = StratifiedShuffleSplit(n_splits=1, test_size=n_samples, random_state=42)\n",
    "        for _, idx in sss.split(X_text, y):\n",
    "            return X_text[idx], X_image[idx], y[idx]\n",
    "    else:\n",
    "        # Échantillonnage aléatoire\n",
    "        idx = np.random.choice(len(X_text), n_samples, replace=False)\n",
    "        return X_text[idx], X_image[idx], y[idx]\n",
    "\n",
    "def analyze_class_specific_explanations(shap_values, y_sample, idx_to_category, category_names, top_n=5):\n",
    "    \"\"\"\n",
    "    Analyse les explications SHAP spécifiques à chaque classe\n",
    "    \n",
    "    Args:\n",
    "        shap_values: Valeurs SHAP\n",
    "        y_sample: Vérité terrain pour les échantillons\n",
    "        idx_to_category: Mapping indices -> codes catégorie\n",
    "        category_names: Mapping codes catégorie -> noms\n",
    "        top_n: Nombre de features importantes à afficher\n",
    "        \n",
    "    Returns:\n",
    "        dict: Résultats par classe\n",
    "    \"\"\"\n",
    "    class_results = {}\n",
    "    \n",
    "    # Pour chaque classe\n",
    "    unique_classes = np.unique(y_sample)\n",
    "    for class_idx in unique_classes:\n",
    "        # Convertir l'indice en code et nom de catégorie\n",
    "        category_code = idx_to_category[int(class_idx)]\n",
    "        category_name = category_names[category_code]\n",
    "        \n",
    "        # Filtrer les échantillons de cette classe\n",
    "        class_mask = (y_sample == class_idx)\n",
    "        if np.sum(class_mask) < 5:  # Au moins 5 échantillons\n",
    "            continue\n",
    "            \n",
    "        # Calculer l'importance moyenne des features pour cette classe\n",
    "        class_importance = np.mean(np.abs(shap_values[int(class_idx)][class_mask]), axis=0)\n",
    "        \n",
    "        # Trouver les top features\n",
    "        top_indices = np.argsort(class_importance)[-top_n:][::-1]\n",
    "        top_values = class_importance[top_indices]\n",
    "        \n",
    "        class_results[f\"{category_code}_{category_name}\"] = {\n",
    "            'top_indices': top_indices,\n",
    "            'top_values': top_values\n",
    "        }\n",
    "        \n",
    "        # Créer un graphique pour cette classe\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.barh(range(top_n), top_values)\n",
    "        plt.yticks(range(top_n), [f\"Feature {idx}\" for idx in top_indices])\n",
    "        plt.title(f\"Top {top_n} caractéristiques pour {category_name} (code {category_code})\")\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f\"data/reports/class_{category_code}_top_features.png\")\n",
    "    \n",
    "    return class_results\n",
    "\n",
    "def compare_models_explanations(text_shap, xgboost_shap, mlp_shap, multimodal_shap, y_sample, \n",
    "                               idx_to_category, category_names):\n",
    "    \"\"\"\n",
    "    Compare les explications entre les différents modèles\n",
    "    \n",
    "    Args:\n",
    "        text_shap: Valeurs SHAP du modèle texte\n",
    "        xgboost_shap: Valeurs SHAP du modèle XGBoost\n",
    "        mlp_shap: Valeurs SHAP du modèle MLP\n",
    "        multimodal_shap: Valeurs SHAP du modèle multimodal\n",
    "        y_sample: Vérité terrain pour les échantillons\n",
    "        idx_to_category: Mapping indices -> codes catégorie\n",
    "        category_names: Mapping codes catégorie -> noms\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: Comparaison des explications\n",
    "    \"\"\"\n",
    "    # Initialiser le DataFrame de résultats\n",
    "    results = []\n",
    "    \n",
    "    # Pour chaque classe\n",
    "    unique_classes = np.unique(y_sample)\n",
    "    for class_idx in unique_classes:\n",
    "        # Convertir l'indice en code et nom de catégorie\n",
    "        category_code = idx_to_category[int(class_idx)]\n",
    "        category_name = category_names[category_code]\n",
    "        \n",
    "        # Filtrer les échantillons de cette classe\n",
    "        class_mask = (y_sample == class_idx)\n",
    "        if np.sum(class_mask) < 5:  # Au moins 5 échantillons\n",
    "            continue\n",
    "            \n",
    "        # Calculer la magnitude SHAP moyenne pour chaque modèle\n",
    "        text_magnitude = np.mean(np.abs(text_shap[int(class_idx)][class_mask]))\n",
    "        xgb_magnitude = np.mean(np.abs(xgboost_shap[int(class_idx)][class_mask]))\n",
    "        mlp_magnitude = np.mean(np.abs(mlp_shap[int(class_idx)][class_mask]))\n",
    "        multi_magnitude = np.mean(np.abs(multimodal_shap[int(class_idx)][class_mask]))\n",
    "        \n",
    "        # Déterminer la modalité dominante\n",
    "        modality = \"Texte\" if text_magnitude > (xgb_magnitude + mlp_magnitude)/2 else \"Image\"\n",
    "        model_rank = sorted(['Texte', 'XGBoost', 'MLP', 'Multimodal'], \n",
    "                          key=lambda x: {'Texte': text_magnitude, 'XGBoost': xgb_magnitude, \n",
    "                                         'MLP': mlp_magnitude, 'Multimodal': multi_magnitude}[x],\n",
    "                          reverse=True)\n",
    "        \n",
    "        # Ajouter aux résultats\n",
    "        results.append({\n",
    "            'category_code': category_code,\n",
    "            'category_name': category_name,\n",
    "            'samples': np.sum(class_mask),\n",
    "            'text_magnitude': text_magnitude,\n",
    "            'xgboost_magnitude': xgb_magnitude,\n",
    "            'mlp_magnitude': mlp_magnitude, \n",
    "            'multimodal_magnitude': multi_magnitude,\n",
    "            'dominant_modality': modality,\n",
    "            'best_model': model_rank[0],\n",
    "            'model_ranking': ', '.join(model_rank)\n",
    "        })\n",
    "    \n",
    "    # Convertir en DataFrame\n",
    "    results_df = pd.DataFrame(results)\n",
    "    \n",
    "    # Créer un graphique comparatif des magnitudes par classe\n",
    "    plt.figure(figsize=(16, 10))\n",
    "    categories = results_df['category_name']\n",
    "    \n",
    "    x = np.arange(len(categories))\n",
    "    width = 0.2\n",
    "    \n",
    "    plt.bar(x - 1.5*width, results_df['text_magnitude'], width, label='Texte')\n",
    "    plt.bar(x - 0.5*width, results_df['xgboost_magnitude'], width, label='XGBoost')\n",
    "    plt.bar(x + 0.5*width, results_df['mlp_magnitude'], width, label='MLP')\n",
    "    plt.bar(x + 1.5*width, results_df['multimodal_magnitude'], width, label='Multimodal')\n",
    "    \n",
    "    plt.xlabel('Catégorie')\n",
    "    plt.ylabel('Magnitude SHAP moyenne')\n",
    "    plt.title('Comparaison des explications SHAP par catégorie et modèle')\n",
    "    plt.xticks(x, categories, rotation=90)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"data/reports/shap_magnitude_comparison.png\")\n",
    "    \n",
    "    return results_df\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"1. Configuration et chargement des données..\")\n",
    "    # 1. Configuration et chargement des données\n",
    "    config = PipelineConfig.from_yaml('config.yaml')\n",
    "    pipeline = ProductClassificationPipeline(config)\n",
    "    \n",
    "    try:\n",
    "        # Préparer les données\n",
    "        force_preprocess_image = False\n",
    "        force_preprocess_texte = False\n",
    "        pipeline.prepare_data(force_preprocess_image=force_preprocess_image, force_preprocess_text=force_preprocess_texte)\n",
    "        \n",
    "        # Sauvegarde des indices pour les tests de prod/exam à venir\n",
    "        indices_dict = pipeline.extract_and_save_indices()\n",
    "\n",
    "        # Créer les répertoires de résultats et rapports\n",
    "        os.makedirs('data/reports', exist_ok=True)\n",
    "        os.makedirs('data/explanations', exist_ok=True)\n",
    "        \n",
    "        print(\"2. Charger les modèles pré-entraînés..\")\n",
    "        # 2. Charger les modèles pré-entraînés\n",
    "        models = load_models(pipeline, model_names=['xgboost', 'neural_net'])\n",
    "\n",
    "        # Charger le modèle SVM texte pré-entraîné\n",
    "        from joblib import load\n",
    "        import pandas as pd\n",
    "\n",
    "        # Fonction pour prétraiter le texte comme pour l'entraînement\n",
    "        def preprocess_text(df):\n",
    "            \"\"\"Prétraite les colonnes texte comme lors de l'entraînement\"\"\"\n",
    "            if isinstance(df, pd.DataFrame):\n",
    "                # Si c'est un DataFrame, fusionner designation et description\n",
    "                df['text'] = df['designation'].fillna('') + \" \" + df['description'].fillna('')\n",
    "                return df['text']\n",
    "            else:\n",
    "                # Si c'est déjà une série ou une liste de textes\n",
    "                return df\n",
    "\n",
    "        # Charger le modèle SVM\n",
    "        try:\n",
    "            text_model = load('data/models/SVM/model.pkl')\n",
    "            print(\"Modèle SVM texte chargé avec succès\")\n",
    "            models['SVM'] = text_model\n",
    "        except Exception as e:\n",
    "            print(f\"Erreur lors du chargement du modèle texte: {str(e)}\")\n",
    "            # Utiliser un modèle factice en cas d'erreur\n",
    "            class DummySVM:\n",
    "                def __init__(self, num_classes):\n",
    "                    self.num_classes = num_classes\n",
    "                    \n",
    "                def predict(self, X):\n",
    "                    preds = np.random.randint(0, self.num_classes, size=len(X))\n",
    "                    probs = np.random.random((len(X), self.num_classes))\n",
    "                    probs = probs / probs.sum(axis=1, keepdims=True)\n",
    "                    return preds, probs\n",
    "                        \n",
    "                def predict_proba(self, X):\n",
    "                    probs = np.random.random((len(X), self.num_classes))\n",
    "                    return probs / probs.sum(axis=1, keepdims=True)\n",
    "            \n",
    "            text_model = DummySVM(num_classes=len(pipeline.category_names))\n",
    "            models['SVM'] = text_model\n",
    "            print(\"Utilisation d'un modèle de secours pour le texte\")\n",
    "        \n",
    "        print(\"3. Préparer les données texte pour l'évaluation..\")\n",
    "        # 3. Préparer les données texte pour l'évaluation        \n",
    "        # Obtenir les indices du split de test\n",
    "        test_split_indices = pipeline.preprocessed_data['test_split_indices']\n",
    "        # print(\"test_split_indices:\",test_split_indices)\n",
    "\n",
    "        # Lire les données d'origine\n",
    "        X_train_df = pd.read_csv('data/X_train_update.csv', index_col=0)\n",
    "        # print(f\"X_train_df.index: {X_train_df.index}\")\n",
    "        \n",
    "        # Créer un nouvel index pour X_train_df et un mappage vers les anciens indices\n",
    "        X_train_df_reset = X_train_df.reset_index()\n",
    "        index_map = dict(zip(X_train_df.index, range(len(X_train_df))))\n",
    "        \n",
    "        # Filtrer les indices valides ou utiliser un échantillon représentatif\n",
    "        valid_indices = [idx for idx in test_split_indices if idx in X_train_df.index]\n",
    "        \n",
    "        if len(valid_indices) > 0:\n",
    "            # Utiliser les indices valides\n",
    "            X_test_split_df = X_train_df.loc[valid_indices]\n",
    "            print(f\"Utilisation de {len(valid_indices)}/{len(test_split_indices)} indices valides\")\n",
    "        else:\n",
    "            # Utiliser un échantillon aléatoire de même taille\n",
    "            sample_size = len(test_split_indices)\n",
    "            random_indices = np.random.choice(len(X_train_df), size=sample_size, replace=False)\n",
    "            X_test_split_df = X_train_df.iloc[random_indices]\n",
    "            print(f\"Utilisation d'un échantillon aléatoire de {sample_size} éléments\")\n",
    "        \n",
    "        # Prétraiter le texte\n",
    "        X_text = preprocess_text(X_test_split_df)\n",
    "        \n",
    "        print(\"4. Préparation des données image.. \")\n",
    "        # 4. Préparation des données image\n",
    "        X_image_raw = pipeline.preprocessed_data['X_test_split']\n",
    "        \n",
    "        # Extraire les features d'image correctement\n",
    "        if isinstance(X_image_raw, np.ndarray) and X_image_raw.shape == ():\n",
    "            # C'est un array 0-dimensionnel, extraire son contenu\n",
    "            content = X_image_raw.item()\n",
    "            if isinstance(content, dict) and 'features' in content:\n",
    "                X_image = content['features']\n",
    "            else:\n",
    "                # Tentative avec d'autres clés possibles\n",
    "                if isinstance(content, dict):\n",
    "                    print(f\"Clés disponibles: {list(content.keys())}\")\n",
    "                    possible_keys = ['features', 'X_test_split', 'data']\n",
    "                    for key in possible_keys:\n",
    "                        if key in content:\n",
    "                            X_image = content[key]\n",
    "                            break\n",
    "                else:\n",
    "                    # En dernier recours, utiliser un array aléatoire\n",
    "                    X_image = np.random.random((len(X_text), 2048))\n",
    "        else:\n",
    "            X_image = X_image_raw\n",
    "            \n",
    "        print(f\"Shape de X_image: {X_image.shape if hasattr(X_image, 'shape') else 'inconnu'}\")\n",
    "        \n",
    "        # Assurer que X_text, X_image et y_test ont les mêmes dimensions\n",
    "        y_test = pipeline.preprocessed_data['y_test_split']\n",
    "        \n",
    "        # Vérifier et ajuster les dimensions\n",
    "        sample_sizes = [len(X_text)]\n",
    "        if hasattr(X_image, 'shape'):\n",
    "            sample_sizes.append(X_image.shape[0])\n",
    "        sample_sizes.append(len(y_test))\n",
    "        \n",
    "        min_size = min(sample_sizes)\n",
    "        X_text = X_text.iloc[:min_size] if isinstance(X_text, pd.Series) else X_text[:min_size]\n",
    "        X_image = X_image[:min_size]\n",
    "        y_test = y_test[:min_size]\n",
    "        \n",
    "        print(f\"Dimensions finales: X_text={len(X_text)}, X_image={X_image.shape}, y_test={len(y_test)}\")\n",
    "        \n",
    "        \n",
    "        print(\"5. Évaluer les combinaisons multimodales\")\n",
    "        # 5. Évaluer les combinaisons multimodales        \n",
    "        print(f\"Shape de X_image_test: {X_image.shape if hasattr(X_image, 'shape') else 'pas de forme'}\")\n",
    "        print(f\"Type interne: {X_image.dtype if hasattr(X_image, 'dtype') else 'pas de dtype'}\")\n",
    "\n",
    "        results_df = evaluate_multimodal_combinations(\n",
    "            pipeline=pipeline,\n",
    "            text_model=models['SVM'],\n",
    "            image_models={'xgboost': models['xgboost'], 'neural_net': models['neural_net']},\n",
    "            X_text_test=X_text,\n",
    "            X_image_test=X_image,\n",
    "            y_test=y_test,\n",
    "            idx_to_category=pipeline.idx_to_category\n",
    "        )\n",
    "        \n",
    "        # Sauvegarde des résultats\n",
    "        results_df.to_csv('data/reports/multimodal_comparison_results.csv')\n",
    "        \n",
    "        # Identifier la meilleure combinaison\n",
    "        best_combo = results_df['weighted_f1'].idxmax()\n",
    "        print(f\"\\nLa meilleure combinaison est: {best_combo} avec F1 = {results_df.loc[best_combo, 'weighted_f1']:.4f}\")\n",
    "        \n",
    "        print(\"6. Échantillonner des données pour explication..\")\n",
    "        # 6. Échantillonner des données pour explication\n",
    "        X_text_sample, X_image_sample, y_sample = sample_data_for_explanation(\n",
    "            X_text, X_image, y_test, n_samples=100\n",
    "        )\n",
    "        \n",
    "        print(\"7. Générer des explications pour les modèles individuels..\")\n",
    "        # 7. Générer des explications pour les modèles individuels\n",
    "        text_shap, text_explainer = explain_text_model(\n",
    "            text_model=models['SVM'],\n",
    "            X_text_sample=X_text_sample\n",
    "        )\n",
    "        \n",
    "        xgboost_shap, xgb_explainer = explain_image_model(\n",
    "            model_type='xgboost',\n",
    "            model=models['xgboost'],\n",
    "            X_image_sample=X_image_sample\n",
    "        )\n",
    "        \n",
    "        mlp_shap, mlp_explainer = explain_image_model(\n",
    "            model_type='neural_net',\n",
    "            model=models['neural_net'],\n",
    "            X_image_sample=X_image_sample\n",
    "        )\n",
    "        \n",
    "        print(\"8. Expliquer le modèle multimodal (pour la meilleure combinaison)..\")\n",
    "        # 8. Expliquer le modèle multimodal (pour la meilleure combinaison)\n",
    "        best_model_type = best_combo.split('_')[0]  # Extraire le type de modèle\n",
    "        best_fusion = '_'.join(best_combo.split('_')[1:])  # Extraire la stratégie de fusion\n",
    "        \n",
    "        multimodal_results = explain_multimodal(\n",
    "            text_model=models['SVM'],\n",
    "            image_model=models[best_model_type],\n",
    "            model_type=best_model_type,\n",
    "            X_text_sample=X_text_sample,\n",
    "            X_image_sample=X_image_sample,\n",
    "            fusion_strategy=best_fusion,\n",
    "            class_names=pipeline.category_names\n",
    "        )\n",
    "        \n",
    "        print(\"9. Analyser les explications par classe..\")\n",
    "        # 9. Analyser les explications par classe\n",
    "        class_results = analyze_class_specific_explanations(\n",
    "            shap_values=multimodal_results['shap_values'],\n",
    "            y_sample=y_sample,\n",
    "            idx_to_category=pipeline.idx_to_category,\n",
    "            category_names=pipeline.category_names\n",
    "        )\n",
    "        \n",
    "        print(\"10. Comparer les explicabilités des différents modèles..\")\n",
    "        # 10. Comparer les explicabilités des différents modèles\n",
    "        comparison_df = compare_models_explanations(\n",
    "            text_shap=text_shap,\n",
    "            xgboost_shap=xgboost_shap,\n",
    "            mlp_shap=mlp_shap,\n",
    "            multimodal_shap=multimodal_results['shap_values'],\n",
    "            y_sample=y_sample,\n",
    "            idx_to_category=pipeline.idx_to_category,\n",
    "            category_names=pipeline.category_names\n",
    "        )\n",
    "        \n",
    "        # Sauvegarde des résultats\n",
    "        comparison_df.to_csv('data/reports/model_explanation_comparison.csv')\n",
    "        \n",
    "        print(\"11. Préparation rapport final..\")\n",
    "        # 11. Préparation rapport final\n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "        print(\"RAPPORT FINAL D'ANALYSE MULTIMODALE\")\n",
    "        print(\"=\"*50)\n",
    "        \n",
    "        print(f\"\\n1. PERFORMANCES DES MODÈLES:\")\n",
    "        print(\"-\"*30)\n",
    "        print(results_df.sort_values('weighted_f1', ascending=False))\n",
    "        \n",
    "        print(f\"\\n2. IMPORTANCE RELATIVE DES MODALITÉS:\")\n",
    "        print(\"-\"*30)\n",
    "        print(f\"Texte: {multimodal_results['importance']['text_percentage']:.2f}%\")\n",
    "        print(f\"Image: {multimodal_results['importance']['image_percentage']:.2f}%\")\n",
    "        \n",
    "        print(f\"\\n3. MODALITÉ DOMINANTE PAR CLASSE:\")\n",
    "        print(\"-\"*30)\n",
    "        print(comparison_df[['category_name', 'dominant_modality', 'best_model']].sort_values('category_name'))\n",
    "        \n",
    "        print(f\"\\n4. RECOMMANDATION FINALE:\")\n",
    "        print(\"-\"*30)\n",
    "        if best_model_type == 'xgboost':\n",
    "            print(\"Recommandation: Utiliser XGBoost pour le modèle image\")\n",
    "            print(\"Raisons:\")\n",
    "            print(\"- Meilleures performances multimodales\")\n",
    "            print(\"- Meilleure explicabilité (TreeExplainer natif)\")\n",
    "            print(\"- Plus rapide en inférence\")\n",
    "        else:\n",
    "            print(\"Recommandation: Utiliser Neural Network pour le modèle image\")\n",
    "            print(\"Raisons:\")\n",
    "            print(\"- Meilleures performances multimodales\")\n",
    "            print(\"- Capable de capturer des motifs plus complexes\")\n",
    "        \n",
    "        print(\"\\nGraphiques d'analyse sauvegardés dans data/reports/\")\n",
    "        print(\"Rapports détaillés sauvegardés dans data/reports/\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Erreur lors de l'exécution: {str(e)}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30f40413",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Après avoir exécuté prepare_data\n",
    "# indices_dict = pipeline.extract_and_save_indices()\n",
    "\n",
    "# Plus tard, pour charger et utiliser ces indices\n",
    "test_indices = np.load('data/indices/test_split_indices.npy')\n",
    "ignored_indices = np.load('data/indices/ignored_indices.npy')\n",
    "\n",
    "# Pour des analyses ou tests spécifiques\n",
    "ignored_samples = X_train_df.loc[ignored_indices]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
