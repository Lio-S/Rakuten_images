# model_configs.yaml
xgboost:
  max_depth: 9
  learning_rate: 0.08
  n_estimators: 300
  min_child_weight: 4
  gamma: 0.12
  subsample: 0.8
  colsample_bytree: 0.8
  reg_alpha: 0.2
  reg_lambda: 1.8
  objective: multi:softprob
  num_class: 27
  tree_method: hist
  max_bin: 256
  device: cuda
  n_jobs: 7
  seed: 42
  eval_metric: mlogloss


neural_net:
  batch_size: 48
  learning_rate: 0.0003
  epochs: 60
  dropout_rate: 0.35
  early_stopping_patience: 7
  weight_decay: 0.015
  optimizer_params:
    betas: [0.9, 0.999]
    eps: 1e-8
  scheduler_params:
    factor: 0.15
    patience: 5
    min_lr: 5e-7
  dataloader_params:
    num_workers: 7
    pin_memory: true
    prefetch_factor: 2
    persistent_workers: true

