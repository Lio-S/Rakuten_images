{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "737d30b9-3dd2-4413-8216-10498aab0527",
   "metadata": {},
   "source": [
    "# Meilleur essai avec transfo en pickle du modèle !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b99d1bc-300d-4dd3-8f10-027e25215ed7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training of the SVM model...\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import joblib\n",
    "import numpy as np\n",
    "\n",
    "# Chargement des données\n",
    "X_train = pd.read_csv(\"data/X_train_update.csv\", index_col=0)\n",
    "Y_train = pd.read_csv(\"data/Y_train_CVw08PX.csv\", index_col=0)\n",
    "X_test = pd.read_csv(\"data/X_test_update.csv\", index_col=0)\n",
    "\n",
    "# Fusion des colonnes textuelles\n",
    "X_train['text'] = X_train['designation'].fillna('') + \" \" + X_train['description'].fillna('')\n",
    "X_test['text'] = X_test['designation'].fillna('') + \" \" + X_test['description'].fillna('')\n",
    "\n",
    "# ======= SYNCHRONISATION DES INDICES =======\n",
    "# Charger les indices test_split si disponibles\n",
    "test_split_file = 'data/processed_data/test_split_indices.npz'\n",
    "try:\n",
    "    test_split_indices = np.load(test_split_file, allow_pickle=True)['arr_0']\n",
    "    print(f\"Indices test_split chargés: {len(test_split_indices)} exemples\")\n",
    "    \n",
    "    # Vérifier que les indices sont dans X_train\n",
    "    valid_indices = [idx for idx in test_split_indices if idx in X_train.index]\n",
    "    if len(valid_indices) < len(test_split_indices):\n",
    "        print(f\"Attention: seulement {len(valid_indices)}/{len(test_split_indices)} indices sont valides\")\n",
    "    \n",
    "    # Créer le split train/test en utilisant ces indices\n",
    "    test_mask = X_train.index.isin(valid_indices)\n",
    "    X_train_split = X_train.loc[~test_mask, 'text']\n",
    "    X_val_split = X_train.loc[test_mask, 'text']\n",
    "    y_train_split = Y_train.loc[~test_mask].values.ravel()\n",
    "    y_val_split = Y_train.loc[test_mask].values.ravel()\n",
    "    \n",
    "    print(f\"Division synchronisée: {len(X_train_split)} exemples d'entraînement, {len(X_val_split)} exemples de test\")\n",
    "    \n",
    "except (FileNotFoundError, KeyError):\n",
    "    print(\"Fichier d'indices test_split non trouvé, utilisation de train_test_split standard\")\n",
    "    # Séparer 20% des données pour validation (même ratio que dans le pipeline image)\n",
    "    X_train_split, X_val_split, y_train_split, y_val_split = train_test_split(\n",
    "        X_train['text'], Y_train.values.ravel(), test_size=0.2, random_state=42\n",
    "    )\n",
    "    # Sauvegarder ces indices pour synchronisation future\n",
    "    test_indices = X_train.index[X_train['text'].isin(X_val_split)].values\n",
    "    os.makedirs(os.path.dirname(test_split_file), exist_ok=True)\n",
    "    np.savez(test_split_file, arr_0=test_indices)\n",
    "    print(f\"Nouveaux indices test_split sauvegardés: {len(test_indices)} exemples\")\n",
    "\n",
    "# Définir le pipeline SVM\n",
    "pipeline_svm = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(max_features=45000)),\n",
    "    ('model', SVC(C=12, kernel='rbf', gamma='scale', probability=True, class_weight='balanced'))\n",
    "])\n",
    "\n",
    "# Entraîner le pipeline\n",
    "print(\"Starting training of the SVM model...\")\n",
    "pipeline_svm.fit(X_train_split, y_train_split)\n",
    "print(\"Training completed!\")\n",
    "\n",
    "# Évaluer le modèle\n",
    "y_pred_val = pipeline_svm.predict(X_val_split)\n",
    "print(\"Evaluation of the model on validation set:\")\n",
    "print(classification_report(y_val_split, y_pred_val, zero_division=0))\n",
    "print(f\"Accuracy on validation set: {accuracy_score(y_val_split, y_pred_val)}\")\n",
    "\n",
    "# Sauvegarde du modèle\n",
    "print(\"Saving the trained model...\")\n",
    "os.makedirs('data/models/SVM', exist_ok=True)\n",
    "joblib.dump(pipeline_svm, \"data/models/SVM/model.pkl\")\n",
    "print(\"Model saved as 'data/models/SVM/model.pkl'.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
