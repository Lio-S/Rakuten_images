{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "737d30b9-3dd2-4413-8216-10498aab0527",
   "metadata": {},
   "source": [
    "# Meilleur essai avec transfo en pickle du modèle !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4b99d1bc-300d-4dd3-8f10-027e25215ed7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indices test_split chargés: 16984 exemples\n",
      "Division synchronisée: 67932 exemples d'entraînement, 16984 exemples de test\n",
      "Starting training of the SVM model...\n",
      "Training completed!\n",
      "Evaluation of the model on validation set:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          10       0.47      0.67      0.55       623\n",
      "          40       0.75      0.69      0.72       502\n",
      "          50       0.82      0.85      0.83       336\n",
      "          60       0.99      0.80      0.88       166\n",
      "        1140       0.80      0.83      0.81       534\n",
      "        1160       0.96      0.95      0.95       791\n",
      "        1180       0.86      0.52      0.64       153\n",
      "        1280       0.70      0.71      0.70       974\n",
      "        1281       0.65      0.56      0.60       414\n",
      "        1300       0.94      0.93      0.94      1009\n",
      "        1301       0.97      0.94      0.96       161\n",
      "        1302       0.87      0.74      0.80       498\n",
      "        1320       0.85      0.83      0.84       648\n",
      "        1560       0.83      0.86      0.84      1015\n",
      "        1920       0.92      0.90      0.91       861\n",
      "        1940       0.97      0.89      0.93       161\n",
      "        2060       0.83      0.83      0.83       999\n",
      "        2220       0.98      0.76      0.86       165\n",
      "        2280       0.75      0.84      0.79       952\n",
      "        2403       0.76      0.75      0.75       955\n",
      "        2462       0.84      0.79      0.81       284\n",
      "        2522       0.94      0.93      0.94       998\n",
      "        2582       0.82      0.75      0.78       518\n",
      "        2583       0.97      0.98      0.98      2042\n",
      "        2585       0.83      0.81      0.82       499\n",
      "        2705       0.76      0.72      0.74       552\n",
      "        2905       0.99      0.96      0.97       174\n",
      "\n",
      "    accuracy                           0.83     16984\n",
      "   macro avg       0.84      0.81      0.82     16984\n",
      "weighted avg       0.84      0.83      0.83     16984\n",
      "\n",
      "Accuracy on validation set: 0.833078191238813\n",
      "Saving the trained model...\n",
      "Model saved as 'data/models/SVM/model.pkl'.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import joblib\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Chargement des données\n",
    "X_train = pd.read_csv(\"data/X_train_update.csv\", index_col=0)\n",
    "Y_train = pd.read_csv(\"data/Y_train_CVw08PX.csv\", index_col=0)\n",
    "X_test = pd.read_csv(\"data/X_test_update.csv\", index_col=0)\n",
    "\n",
    "# Fusion des colonnes textuelles\n",
    "X_train['text'] = X_train['designation'].fillna('') + \" \" + X_train['description'].fillna('')\n",
    "X_test['text'] = X_test['designation'].fillna('') + \" \" + X_test['description'].fillna('')\n",
    "\n",
    "# ======= SYNCHRONISATION DES INDICES =======\n",
    "# Charger les indices test_split si disponibles\n",
    "test_split_file = 'data/processed_data/test_split_indices.npz'\n",
    "try:\n",
    "    test_split_indices = np.load(test_split_file, allow_pickle=True)['arr_0']\n",
    "    print(f\"Indices test_split chargés: {len(test_split_indices)} exemples\")\n",
    "    \n",
    "    # Vérifier que les indices sont dans X_train\n",
    "    valid_indices = [idx for idx in test_split_indices if idx in X_train.index]\n",
    "    if len(valid_indices) < len(test_split_indices):\n",
    "        print(f\"Attention: seulement {len(valid_indices)}/{len(test_split_indices)} indices sont valides\")\n",
    "    \n",
    "    # Créer le split train/test en utilisant ces indices\n",
    "    test_mask = X_train.index.isin(valid_indices)\n",
    "    X_train_split = X_train.loc[~test_mask, 'text']\n",
    "    X_val_split = X_train.loc[test_mask, 'text']\n",
    "    y_train_split = Y_train.loc[~test_mask].values.ravel()\n",
    "    y_val_split = Y_train.loc[test_mask].values.ravel()\n",
    "    \n",
    "    print(f\"Division synchronisée: {len(X_train_split)} exemples d'entraînement, {len(X_val_split)} exemples de test\")\n",
    "    \n",
    "except (FileNotFoundError, KeyError):\n",
    "    print(\"Fichier d'indices test_split non trouvé, utilisation de train_test_split standard\")\n",
    "    # Séparer 20% des données pour validation (même ratio que dans le pipeline image)\n",
    "    X_train_split, X_val_split, y_train_split, y_val_split = train_test_split(\n",
    "        X_train['text'], Y_train.values.ravel(), test_size=0.2, random_state=42\n",
    "    )\n",
    "    # Sauvegarder ces indices pour synchronisation future\n",
    "    import os\n",
    "    test_indices = X_train.index[X_train['text'].isin(X_val_split)].values\n",
    "    os.makedirs(os.path.dirname(test_split_file), exist_ok=True)\n",
    "    np.savez(test_split_file, arr_0=test_indices)\n",
    "    print(f\"Nouveaux indices test_split sauvegardés: {len(test_indices)} exemples\")\n",
    "\n",
    "# Définir le pipeline SVM\n",
    "pipeline_svm = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(max_features=45000)),\n",
    "    ('model', SVC(C=12, kernel='rbf', gamma='scale', probability=True, class_weight='balanced'))\n",
    "])\n",
    "\n",
    "# Entraîner le pipeline\n",
    "print(\"Starting training of the SVM model...\")\n",
    "pipeline_svm.fit(X_train_split, y_train_split)\n",
    "print(\"Training completed!\")\n",
    "\n",
    "# Évaluer le modèle\n",
    "y_pred_val = pipeline_svm.predict(X_val_split)\n",
    "print(\"Evaluation of the model on validation set:\")\n",
    "print(classification_report(y_val_split, y_pred_val, zero_division=0))\n",
    "print(f\"Accuracy on validation set: {accuracy_score(y_val_split, y_pred_val)}\")\n",
    "\n",
    "# Sauvegarde du modèle\n",
    "print(\"Saving the trained model...\")\n",
    "os.makedirs('data/models/SVM', exist_ok=True)\n",
    "joblib.dump(pipeline_svm, \"data/models/SVM/model.pkl\")\n",
    "print(\"Model saved as 'data/models/SVM/model.pkl'.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Rakuten (Python 3.10.12)",
   "language": "python",
   "name": "rakuten-3.10.12"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
